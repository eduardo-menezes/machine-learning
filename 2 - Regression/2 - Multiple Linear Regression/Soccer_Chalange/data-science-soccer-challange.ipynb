{"cells":[{"metadata":{"_uuid":"e337155c-94ad-4b00-b3ef-42a0af26467a","_cell_guid":"e267d168-721f-4b86-be7b-834b2b68ef90","trusted":true},"cell_type":"code","source":"#Desafio de Data Science\n\n# Uma equipe de futebol está reformulando seu elenco e uma das ações planejadas é\n# a aquisição de um goleiro. Essa equipe precisa que você indique o valor de mercado\n# desse goleiro para que eles possam fazer um bom negócio. Usando o conjunto de dados\n# de jogadores de futebol fornecido, crie pelo menos três modelos capazes de auxiliar\n# essa equipe na negociação do jogador e, por fim, escolha o melhor modelo.\n# Considere que o orçamento disponível para esta compra é de até 1 milhão de euros.\n\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\n# Loading the file\ndf = pd.read_csv(\"../input/fifa-dataset/data.csv\")\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19834b06-3bdd-4e8e-bf3f-d2559d7c54f3","_cell_guid":"c4f75480-6346-410d-92ce-ad68b95139e2","trusted":true},"cell_type":"code","source":"# First impressions\n#df.head()\n#df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dbc64c82-a1c6-4d09-a7bd-f2adddd5874a","_cell_guid":"a91e2fc2-d7e6-4cfb-afbd-d29998f87cf1","trusted":true},"cell_type":"code","source":"# dataset dimensionality\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a7aea49-9aea-4239-9c20-60988c912011","_cell_guid":"6c86b4e3-9b36-4011-9d0c-22987b9c7795","trusted":true},"cell_type":"code","source":"# Great, now we need to define our target.\n# We want to acquire a GoalKeeper and define his market price (Value)\n# So, based on this, we'll need all the GoalKeepers information to start analyzing\n# For this, let's extract GoalKeepers information\ndf.Position == \"GK\"\ndf_gk = df.loc[df.Position == \"GK\"]\n\n# Checking our new dimensionality\ndf_gk.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7114c4ef-9c43-4269-8836-168dd33930bf","_cell_guid":"d6a91a1c-2c29-4d9f-9b53-514142a059e7","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eaa71779-d578-41c5-81d9-dfec1af9325c","_cell_guid":"ff8172f4-7ebc-4f74-8a6c-dc66f6dd19ce","trusted":true},"cell_type":"code","source":"# DataFrame information\n#df_gk.info()\n## As we saw in \".info()\" our data has shown not fully-filled\n#  As expected, the data which doesn't represent the GoalKeepers are empty, that is,\n# data from columns 28 to 53","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a52d0f1-8895-4747-b5aa-ae41b7d3d67f","_cell_guid":"f5b5843a-f7cb-4a95-bf47-ec55c363637f","trusted":true},"cell_type":"code","source":"# Let's drop this data\ngk_dataset = df_gk.drop(df_gk.iloc[:,28:54],axis=1)\n#gk_dataset.info()\n#data has been dropped","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c5e862c8-0790-4dff-9f05-264b63f7ff7c","_cell_guid":"5add0dfe-6ac0-4b71-9f58-daefb0ac99c1","trusted":true},"cell_type":"code","source":"#let's save the names and values\nnames = gk_dataset.Name.tolist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db6bdd87-bb4f-422d-8b68-a4481952cf11","_cell_guid":"3f95dd9e-e99c-4618-918c-8e5f5ae9d243","trusted":true},"cell_type":"code","source":"# Heights need to be converted because there's a string\n# Weights contains strings, we need to fix that\n# Let's fix Heights constructing a function that convert it into meter. Thid method\n# seems, by theory, easier now.\ndef ConvertHeights(varh):\n    store = [] # will get the splitted data\n    height = 1 # initializes a Global Variable so we can return a value from a local enviroment\n    if isinstance(varh, str):\n        aux = varh.split(\"'\")\n        feet = int(aux[0])\n        inches = int(aux[1])\n        height = (12*feet+inches)*0.0254\n    return (height)\n\n# now we apply the function in our data\ngk_dataset[\"Height\"] = gk_dataset[\"Height\"].apply(ConvertHeights)\ngk_dataset[\"Height\"].fillna((gk_dataset[\"Height\"].mean()), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"54e697df-b32d-4e06-9aa5-d401123927ae","_cell_guid":"41666a1b-1a17-4bbf-a835-8a8ec16c941f","trusted":true},"cell_type":"code","source":"# Now, the weight\ndef WeightConvert(varw):\n    \n    if isinstance(varw,str):\n        \n        return (varw.replace(\"lbs\",\"\"))\n\ngk_dataset[\"Weight\"] = gk_dataset[\"Weight\"].apply(WeightConvert).astype(\"float\")\ngk_dataset[\"Weight\"].fillna(gk_dataset[\"Weight\"].mean(), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b8d11f03-8db8-4bf3-a9d6-50ad491683d0","_cell_guid":"33d038bd-3d51-4fb4-b77e-f7da3f073846","trusted":true},"cell_type":"code","source":"##Now, let's convert, value, wage and realese clause\n# Defining a function to check if there are \"eurosign\" strings availabe and convert it to nothing\n\ndef V_W_convertion(value):\n    if isinstance(value, str): # Verify if value is intance of string. Returns True|False\n        output = value.replace(\"€\",\"\")\n        if \"M\" in output:\n            output = float(output.replace(\"M\", \"\"))*100000 # put value at units\n        elif \"K\" in value:\n            output = float(output.replace(\"K\",\"\"))*1000 # put value at units\n        return float(output)\n\n# Defined the function, we can apply it to value, wage and realese clause\n# We cam use lambda funcation to win time\n\ngk_dataset[\"Value\"] = gk_dataset[\"Value\"].apply(lambda x: V_W_convertion(x))\n#gk_dataset[\"Value\"] = gk_dataset[\"Value\"].mask(gk_dataset[\"Value\"] == 0,gk_dataset[\"Value\"].mean())\ngk_dataset[\"Wage\"] = gk_dataset[\"Wage\"].apply(lambda x: V_W_convertion(x))\ngk_dataset[\"Release Clause\"] = gk_dataset[\"Release Clause\"].apply(lambda x: V_W_convertion(x))\n\n# As we know, realese clause contains missing values\n# Let's fill with mean value\ngk_dataset[\"Release Clause\"].fillna(gk_dataset[\"Release Clause\"].mean(),inplace=True)\n#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n#gk_dataset\ngk_dataset[\"Value\"]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d8b60f3-fcb2-41c7-807a-406af09b0f27","_cell_guid":"b8de7d2b-927c-4131-b42a-c0a75c91a3c4","trusted":true},"cell_type":"code","source":"# Let's drop now the columns\ngk_dataset.drop([\"ID\",\"Photo\",\"Flag\",\"Club Logo\",\"Real Face\",\"Jersey Number\", \"Loaned From\"],axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fee2b00-adeb-4738-8470-3a11a3c65bfe","_cell_guid":"b2619cb7-fc73-42f0-b57a-e21642701b84","trusted":true},"cell_type":"code","source":"#\ngk_dataset.drop([\"Name\", \"Nationality\",\"Club\",\"Wage\", \"Preferred Foot\", \"Position\", \"Joined\",\"Contract Valid Until\",\"Release Clause\"], axis=1, inplace=True)\n#gk_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"726f21f5-af89-4218-99c2-d37b98fd26ca","_cell_guid":"65229b13-3622-4b84-a260-0197156b4eba","trusted":true},"cell_type":"code","source":"# Right, now we the right data\ngk_dataset.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"caea13e1-2450-4f11-94a6-c83e38eea819","_cell_guid":"664eaecd-ecf4-48ad-bd9b-19aaf8f96eae","trusted":true},"cell_type":"code","source":"# Let's map the categorical data into a numerical data\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\ngk_dataset[\"Body Type\"] = label_encoder.fit_transform(gk_dataset[\"Body Type\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7acb51b-e943-4100-bd6e-3d3b8c04b3c4","_cell_guid":"57817e8b-2d1b-41b0-82d4-4737faff8451","trusted":true},"cell_type":"code","source":"# \"work_rate\" presents two strings into one cell. We need to spit them\nwork_rate_aux = gk_dataset[\"Work Rate\"].str.split(\"/\", n=1, expand=True)\nwork_rate_aux","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d0e87cc-04e2-4766-a441-03d24d2b77e7","_cell_guid":"e8ae912e-2445-4d99-89d3-89264d6a2cd1","trusted":true},"cell_type":"code","source":"# Now we create two new columns for work_rate_aux[0] and work_rate_aux[1] \ngk_dataset[\"Work Rate 1\"] = work_rate_aux[0]\ngk_dataset[\"Work Rate 2\"] = work_rate_aux[1]\n\n#mapping the categorical data into a numerical data\ngk_dataset[\"Work Rate 1\"] = label_encoder.fit_transform(gk_dataset[\"Work Rate 1\"])\ngk_dataset[\"Work Rate 2\"] = label_encoder.fit_transform(gk_dataset[\"Work Rate 2\"])\n# And, finally, drop work rate column\ngk_dataset.drop([\"Work Rate\"], axis=1, inplace=True)\n#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\ngk_dataset.columns\ngk_dataset[\"Skill Moves\"]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f0e5702d-3de6-41ba-9be0-ba1e02ad36be","_cell_guid":"5efa608a-48b8-405d-a205-a95bcc3403e2","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d28d945c-1412-440c-87e8-1a1382e8c2c9","_cell_guid":"3ed6a284-5ba6-49b3-a4e8-9a2f9cadf3f6","trusted":true},"cell_type":"code","source":"#View the correlations\ncorr_mat = gk_dataset.corr()\ncorr_mat","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff1c3c2f-a4a4-4751-b3c2-fb032a4e5eb9","_cell_guid":"044caff9-a4d5-4c57-9f9c-94721d2cffc6","trusted":true},"cell_type":"code","source":"\n#Correlation With Value (most correlated with positive)\npd.DataFrame(corr_mat[\"Value\"]).sort_values(\"Value\", ascending=False).head(50)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c444b5f-c518-425f-841f-5a2d4d77a93b","_cell_guid":"1412510a-9559-4987-ad20-9198bd6d0b32","trusted":true},"cell_type":"code","source":"#Correlation With Value (modes correlated with negative)\npd.DataFrame(corr_mat[\"Value\"]).sort_values(\"Value\", ascending=True).head(7)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f19ee5b-0ce0-4b28-99b8-7521096adb32","_cell_guid":"cb8e6ec9-ffd7-46f2-b856-fdd6701d0c31","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a29cf58-0c89-46a0-ac21-1ddf96723e48","_cell_guid":"10ab7609-1b3e-41b0-9683-081f4f597c30","trusted":true},"cell_type":"code","source":"inputs = gk_dataset[['Age', 'Overall', 'Potential', 'Special',\n       'International Reputation', 'Weak Foot', 'Skill Moves', 'Body Type',\n       'Height', 'Weight', 'Crossing', 'Finishing', 'HeadingAccuracy',\n       'ShortPassing', 'Volleys', 'Dribbling', 'Curve', 'FKAccuracy',\n       'LongPassing', 'BallControl', 'Acceleration', 'SprintSpeed', 'Agility',\n       'Reactions', 'Balance', 'ShotPower', 'Jumping', 'Stamina', 'Strength',\n       'LongShots', 'Aggression', 'Interceptions', 'Positioning', 'Vision',\n       'Penalties', 'Composure', 'Marking', 'StandingTackle', 'SlidingTackle',\n       'GKDiving', 'GKHandling', 'GKKicking', 'GKPositioning', 'GKReflexes',\n       'Work Rate 1', 'Work Rate 2']]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b252883-871c-445a-ad44-6fa0ebb76161","_cell_guid":"c5376f2b-fcdd-4f7b-ba24-46213aab144b","trusted":true},"cell_type":"code","source":"# Here, we have features available and target available. Therefore, we have supervised learning.\n# We have to decide if it's a Regression problem or Classification problem.\n# In Regression, we have continuos values and in Classification we have discrete values.\n# Based on that, let's verify our target value\ntarget = np.log1p(gk_dataset[\"Value\"]) # high values - skewness\ntarget\nsns.distplot(target,kde=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"66d1ae4a-08ea-4a7b-8739-455eacfdddd9","_cell_guid":"fef25bd5-8220-4a43-a5dd-547efa883f8f","trusted":true},"cell_type":"code","source":"## As we can see, the distribution lies between 7 to 17\n# Therefore, let's focus at this range and forget these outliers\ntarget_index = target[target>7].index\ninputs = inputs.loc[target_index]\ntarget = target[target>7]\nprint(inputs.shape,target.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0078799d-75cf-4e59-ad3b-9d2cc3cb48e1","_cell_guid":"a6aa4764-0248-4e1a-9a32-3f2775c86185","trusted":true},"cell_type":"code","source":"# We have 46 features, let's reduce them \nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import Lasso\nfrom sklearn.preprocessing import LabelEncoder,MinMaxScaler\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\n# Normalizing the data\ninputs_scaled = MinMaxScaler().fit_transform(inputs)\nf_selection = SelectFromModel(Lasso(alpha=0.0001, random_state=41))\nf_selection.fit(inputs_scaled, target)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3afc404f-8a7e-426f-a6b6-be2bb06d3973","_cell_guid":"f89aeb2f-a7f6-4e33-b904-204aeed2fe0f","trusted":true},"cell_type":"code","source":"\n\n\nf_selection.get_support() # get index of the features selected","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a126d21-72f3-4189-b9e5-ba46daea3fad","_cell_guid":"3472d6ef-6493-4058-b8b5-a0292b17e4e1","trusted":true},"cell_type":"code","source":"selected_features = inputs.columns[(f_selection.get_support())]\nselected_features","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e1b16cb6-355f-4823-907f-a12bf61669e8","_cell_guid":"255dcba9-29f9-4e7b-b1b6-d4e11b26c2af","trusted":true},"cell_type":"code","source":"#Based on that, we can take some conclusions\nprint(\"Total Features: {}\".format((inputs.shape[1])))\nprint(\"Selected Features: {}\".format(len(selected_features)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b5dcfb9d-1a0d-49e9-b1f5-f3e64f049a08","_cell_guid":"ec21761d-5e6d-4ede-974f-59f32e7abca0","trusted":true},"cell_type":"code","source":"## Ok, let's build our model\n# First we need to split our data into train-test data\nfrom sklearn.model_selection import train_test_split\nx_model = inputs[selected_features] \nx_model.shape #check\nxtrain,xtest,ytrain,ytest = train_test_split(x_model,target,test_size=0.3,random_state=41)\nprint(xtrain.shape,xtest.shape,ytrain.shape,ytest.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b6ecd09-3c98-4fca-8579-19f6258a984b","_cell_guid":"c2b5c5ce-9566-4ecb-9c98-9869ac45bdc2","trusted":true},"cell_type":"code","source":"## Let's create a function that retuns some informations\nfrom sklearn.metrics import mean_squared_error, explained_variance_score, r2_score\n\ndef plot_analisys(y,ypred,figsize=(10,4), title=\"\"):\n    #setting\n    fig,axs = plt.subplots(1,2,figsize=figsize)\n    \n    #defing the type of plot in axs[0]\n    axs[0].scatter(y,ypred)\n    \n    #defing the boundries\n    mn = min(np.min(y),np.min(ypred))\n    mx = max(np.max(y),np.max(ypred))\n    axs[0].plot([mn,mx],[mn,mx], c=\"red\")\n    \n    #setting labels\n    axs[0].set_xlabel(\"$y$\")\n    axs[0].set_ylabel(\"$\\hat{y}$\")\n    \n    #Calculating statistics\n    rmse = np.sqrt(mean_squared_error(y,ypred))\n    evs = explained_variance_score(y,ypred)\n    r2 = r2_score(y,ypred)\n    \n    # String format axs0\n    axs[0].set_title(\"rmse = {:.2f}, evs = {:.2f}, r2 = {:,.2f}\".format(rmse,evs,r2))\n    \n    #defing the type of plot in axs[1]\n    axs[1].hist(y-ypred,bins=50)\n    avg = np.mean(y-ypred)\n    std = np.std(y-ypred)\n    axs[1].set_xlabel(\"$y - \\hat{y}$\")\n    \n    # String format axs1\n    axs[1].set_title(\"Histogram predictor error, $\\mu$ = {:.2f}, $\\sigma$= {:.2f}\".format(avg,std))\n    \n    if title != \"\":\n        fig.suptitle(title)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"310ddc75-5a40-4b2f-a3ca-f5900bbeb09f","_cell_guid":"2131bfc6-c6de-420b-8a00-aeb7aff08f83","trusted":true},"cell_type":"code","source":"# Creating a pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import Lasso,LinearRegression, Ridge,LassoCV, RidgeCV\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn import linear_model\n\nmodel = Pipeline(( (\"standard_Scaler\", StandardScaler()),\n                 (\"poly\", PolynomialFeatures(degree = 2)),\n                 (\"lin_reg\", Lasso(alpha=0.01)) ))\n\n# Training the model\nmodel.fit(xtrain, ytrain)\n\n# Making predictions for the train data\nytrain_pred = model.predict(xtrain)\nplot_analisys(ytrain,ytrain_pred,title = \"Polynomial model - Training set\")\n\n# Making predictions for the test data\nytest_pred = model.predict(xtest)\nplot_analisys(ytest,ytest_pred,title = \"Polynomial model - Test set\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1b689aa7-78c2-46fd-869e-626d01cc6abe","_cell_guid":"a29d902e-94af-48af-916c-d7c5e1b258e8","trusted":true},"cell_type":"code","source":"#set up the 4 models we're choosing from:\n\nlm = LinearRegression()\n\n#Feature scaling for train, val, and test so that we can run our ridge model on each\nscaler = StandardScaler()\n\nX_train_scaled = scaler.fit_transform(xtrain.values)\nX_test_scaled = scaler.transform(xtest.values)\n\nlm_reg = Ridge(alpha=0.05, normalize=True)\n\nlm_lasso = Lasso(alpha=0.05, normalize=True)\n\n\n\nlm.fit(xtrain, ytrain)\nprint(f'Linear Regression for all data R^2: {lm.score(x_model, target):.3f}')\nprint(f'Linear Regression for test data R^2: {lm.score(xtest, ytest):.3f}')\nprint(\"\")\n\nlm_reg.fit(X_train_scaled, ytrain)\nprint(f'Ridge Regression for test data R^2: {lm_reg.score(X_test_scaled, ytest):.3f}')\n\nprint(\"\")\n\n\nlm_lasso.fit(xtrain,ytrain)\nprint(f'Lasso Regression for test data R^2: {lm_lasso.score(xtest, ytest):.6f}')\n\nprint(\"\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9f5c2875-c088-4583-a3b4-5b100d689ffe","_cell_guid":"cd92d3b3-b83f-40e3-a366-164d04abd192","trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nimport statsmodels.formula.api as smf\n#Model based on most selected columns\n\nX1= gk_dataset.loc[:,['Overall', 'Potential','International Reputation','Reactions','GKDiving', 'GKHandling', 'GKKicking',\n                      'GKPositioning', 'GKReflexes']]\ny1= gk_dataset.loc[:,\"Value\"]\n\nplayer_model1 = sm.OLS(y1, X1, data=gk_dataset)\n\nresults1 = player_model1.fit()\n\nprint(results1.summary());","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}